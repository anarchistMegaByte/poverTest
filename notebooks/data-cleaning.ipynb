{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "9d0ba8e1-5f77-4bc6-b77d-e2727a2080f5"
    }
   },
   "outputs": [],
   "source": [
    "#### Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "78f399cb-ed60-423c-a3ad-ce21fdbcfe71"
    }
   },
   "outputs": [],
   "source": [
    "# Load training and test data into pandas dataframes\n",
    "# ACCCESSING DATA FOLDER REFER THIS LINK \n",
    "# (https://stackoverflow.com/questions/7165749/open-file-in-a-relative-location-in-python)\n",
    "\n",
    "import os\n",
    "\n",
    "#TO ACCESS THE PATH IN WHICH CURRENT SCRIPT IS RUNNING\n",
    "fileDir = os.path.dirname(os.path.realpath('__file__'))\n",
    "\n",
    "#For accessing the file inside a sibling folder.\n",
    "#data_type = 'raw' or 'processed'\n",
    "#country   = 'A' or 'B' or 'C'\n",
    "#person_type = 'hhold' or 'indiv'\n",
    "#dataset = 'test' or 'train'\n",
    "\n",
    "def return_file_name(data_type = 'raw', country = 'A', person_type = 'hhold', dataset = 'train'):\n",
    "    path = '../data/' + data_type + '/' + country + '/' + country + '_' + person_type + '_' + dataset +'.csv'\n",
    "    print(\"Building path for file : (\" + path +\")\")\n",
    "    filename = os.path.join(fileDir, path)\n",
    "    filename = os.path.abspath(os.path.realpath(filename))\n",
    "    #print(filename + \"\\n\")\n",
    "    return filename\n",
    "\n",
    "def return_train_test(data_type = 'raw', country = 'A', person_type = 'hhold'):\n",
    "    train = pd.read_csv(return_file_name(data_type = data_type, country = country, person_type = person_type, dataset = 'train'))\n",
    "    test = pd.read_csv(return_file_name(data_type = data_type, country = country, person_type = person_type, dataset = 'test'))\n",
    "    # merge training and test sets into one dataframe\n",
    "    full = pd.concat([train, test])\n",
    "    return train,test,full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "nbpresent": {
     "id": "2ba45402-bd27-488b-94ef-c4bd1d612f01"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building path for file : (../data/raw/A/A_indiv_train.csv)\n",
      "Building path for file : (../data/raw/A/A_indiv_test.csv)\n",
      "\n",
      "Train Shape : (37560, 44)\n",
      "Test Shape : (18535, 43)\n",
      "Full Shape : (56095, 44)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get size of dataframes\n",
    "train_set,test_set,full_set = return_train_test(data_type = 'raw', country = 'A', person_type = 'indiv')\n",
    "\n",
    "#shape[0] -> # of rows\n",
    "#shape[1] -> # of cols\n",
    "print(\"\\nTrain Shape : \" + str(train_set.shape))\n",
    "print(\"Test Shape : \" + str(test_set.shape))\n",
    "print(\"Full Shape : \" + str(full_set.shape) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "nbpresent": {
     "id": "14712d19-8013-4c2c-bfab-3847e9405d45"
    }
   },
   "outputs": [],
   "source": [
    "#Looking for Nans\n",
    "#return a formatted percentage from a fraction\n",
    "def percentage(numerator, denomenator):\n",
    "    \n",
    "    if type(numerator) == pd.core.series.Series:\n",
    "        return (numerator/denomenator*100)\n",
    "    \n",
    "    elif type(numerator) == int or type(numerator) == float:\n",
    "        return '{:.1f}%'.format(float(numerator)/float(denomenator)*100) \n",
    "    \n",
    "    else:\n",
    "        print(\"check type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "nbpresent": {
     "id": "45eff3ce-743c-475c-a626-0b245697f6c2"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OdXpbPGJ    83.473616\n",
       "dtype: float64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get percentage by variable of values which are not NaN\n",
    "def return_bad_cols(dataframe):\n",
    "    fill_precent_counts = percentage(dataframe.count()-1, dataframe.shape[0]-1)\n",
    "    bad_cols = fill_precent_counts[fill_precent_counts < 100]\n",
    "    return bad_cols\n",
    "\n",
    "train_bad_cols = return_bad_cols(train_set)\n",
    "test_bad_cols = return_bad_cols(test_set)\n",
    "test_bad_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "nbpresent": {
     "id": "b5d20bc0-0feb-4883-bdd1-ee3503632aa4"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to create folder for A\n",
      "Trying to create folder for B\n",
      "Trying to create folder for C\n"
     ]
    }
   ],
   "source": [
    "#make directory for asving bad columns statistics\n",
    "# refer link (https://stackoverflow.com/questions/273192/how-can-i-create-a-directory-if-it-does-not-exist)\n",
    "stats_folder_path = '../data/stats/'\n",
    "\n",
    "def make_dir(directory):\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "\n",
    "def create_stats_folder():\n",
    "    for name in ['A', 'B', 'C']:\n",
    "        foldername = os.path.join(fileDir, stats_folder_path + name + '/individual')\n",
    "        foldername = os.path.abspath(os.path.realpath(foldername))\n",
    "        make_dir(foldername)\n",
    "        foldername = os.path.join(fileDir, stats_folder_path + name + '/household')\n",
    "        foldername = os.path.abspath(os.path.realpath(foldername))\n",
    "        make_dir(foldername)\n",
    "        print(\"Trying to create folder for \" + name)\n",
    "        \n",
    "def return_bad_col_dtype(bad_columns, dataframe):\n",
    "    data_type = []\n",
    "    for name in bad_columns:\n",
    "        data_type.append(dataframe[name].dtype)\n",
    "    return data_type\n",
    "\n",
    "create_stats_folder()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_unique_values(bad_columns, dataframe):\n",
    "    unique_vals = []\n",
    "    for name in bad_columns:\n",
    "        vals = dataframe[dataframe[name].notnull()][name].unique()\n",
    "        unique_vals.append(vals.tolist())\n",
    "    return unique_vals\n",
    "\n",
    "def return_max_val_repeated(bad_columns, dataframe):\n",
    "    freq_count_num = []\n",
    "    val_colon_freq_precent = []\n",
    "    for name in bad_columns:\n",
    "        #refer (https://www.w3resource.com/python-exercises/numpy/python-numpy-exercise-94.php)\n",
    "        unique_elements, counts_elements = np.unique(dataframe[dataframe[name].notnull()][name], return_counts=True)\n",
    "        val_with_max_freq = unique_elements[np.argmax(counts_elements)]\n",
    "        max_freq = int(np.max(counts_elements) / np.sum(counts_elements) * 100)\n",
    "        dict_f = {val_with_max_freq : max_freq}\n",
    "    \n",
    "        dict_temp = {}\n",
    "        for val, count in zip(unique_elements, counts_elements):\n",
    "            dict_temp[val] = int(count / np.sum(counts_elements) * 100)\n",
    "        \n",
    "        freq_count_num.append(dict_f)\n",
    "        val_colon_freq_precent.append(dict_temp)\n",
    "    return freq_count_num, val_colon_freq_precent\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "nbpresent": {
     "id": "e7a2e8ae-d7ba-469f-9e06-32655b5e0d66"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n#refer (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\\ntrain_bad_col_data = {'name': train_bad_cols.keys(), 'per_non_nan': train_bad_cols.values}\\ntrain_bad_col_frame = pd.DataFrame(data=train_bad_col_data)\\n\\n#Add data type col\\nbad_col_data_type = return_bad_col_dtype(train_bad_col_frame['name'], train_set)\\ntrain_bad_col_frame['datatype'] = bad_col_data_type\\n\\n#unique vals col (not used)\\nbad_col_unique_vals = return_unique_values(train_bad_col_frame['name'], train_set)\\n#train_bad_col_frame['unique_vals'] = bad_col_unique_vals\\n\\n#show max freq count \\nbad_col_freq_count, temp = return_max_val_repeated(train_bad_col_frame['name'], train_set)\\ntrain_bad_col_frame['freq_count'] = bad_col_freq_count\\ntrain_bad_col_frame['unique_vals_colon_precent'] = temp\\n\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#############################\n",
    "##    data set analysis    ##\n",
    "#############################\n",
    "\n",
    "def data_set_analysis(bad_columns, dataset):\n",
    "    #make a data frame \n",
    "    #refer (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n",
    "    bad_col_data = {'name': bad_columns.keys(), 'per_non_nan': bad_columns.values}\n",
    "    bad_col_frame = pd.DataFrame(data=bad_col_data)\n",
    "    \n",
    "    #Add data type col\n",
    "    bad_col_data_type = return_bad_col_dtype(bad_col_frame['name'], dataset)\n",
    "    bad_col_frame['datatype'] = bad_col_data_type\n",
    "    \n",
    "    #unique vals col (not used)\n",
    "    bad_col_unique_vals = return_unique_values(bad_col_frame['name'], dataset)\n",
    "    #bad_col_frame['unique_vals'] = bad_col_unique_vals\n",
    "\n",
    "    #show max freq count \n",
    "    bad_col_freq_count, temp = return_max_val_repeated(bad_col_frame['name'], dataset)\n",
    "    bad_col_frame['freq_count'] = bad_col_freq_count\n",
    "    bad_col_frame['unique_vals_colon_precent'] = temp\n",
    "\n",
    "    return bad_col_frame\n",
    "    \n",
    "bad_frame_train = data_set_analysis(train_bad_cols, train_set)\n",
    "bad_frame_test = data_set_analysis(test_bad_cols, test_set)\n",
    "#make a data frame \n",
    "'''\n",
    "#refer (https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.html)\n",
    "train_bad_col_data = {'name': train_bad_cols.keys(), 'per_non_nan': train_bad_cols.values}\n",
    "train_bad_col_frame = pd.DataFrame(data=train_bad_col_data)\n",
    "\n",
    "#Add data type col\n",
    "bad_col_data_type = return_bad_col_dtype(train_bad_col_frame['name'], train_set)\n",
    "train_bad_col_frame['datatype'] = bad_col_data_type\n",
    "\n",
    "#unique vals col (not used)\n",
    "bad_col_unique_vals = return_unique_values(train_bad_col_frame['name'], train_set)\n",
    "#train_bad_col_frame['unique_vals'] = bad_col_unique_vals\n",
    "\n",
    "#show max freq count \n",
    "bad_col_freq_count, temp = return_max_val_repeated(train_bad_col_frame['name'], train_set)\n",
    "train_bad_col_frame['freq_count'] = bad_col_freq_count\n",
    "train_bad_col_frame['unique_vals_colon_precent'] = temp\n",
    "'''\n",
    "\n",
    "#train_set[train_set.FGWqGkmD.isnull()].groupby('poor')['poor'].count()\n",
    "#train[train.FGWqGkmD.notnull()].groupby('poor')['poor'].count()\n",
    "\n",
    "#for col_name, precent in zip(train_bad_cols.keys(),train_bad_cols.values):\n",
    "    #print(col_name + \" \" + str(precent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#country = 'A'\n",
    "country = 'B'\n",
    "#country = 'C'\n",
    "\n",
    "type_people = 'household'\n",
    "#type_people = 'individual'\n",
    "\n",
    "stats_name_train = os.path.join(fileDir, stats_folder_path + country + '/'+ type_people + '/' + country +'_' + type_people + '_train.csv')\n",
    "stats_name_train = os.path.abspath(os.path.realpath(stats_name_train))\n",
    "\n",
    "stats_name_test = os.path.join(fileDir, stats_folder_path + country + '/'+ type_people + '/' + country +'_' + type_people + '_test.csv')\n",
    "stats_name_test = os.path.abspath(os.path.realpath(stats_name_test))\n",
    "\n",
    "\n",
    "bad_frame_train.to_csv(stats_name_train, index=False)\n",
    "\n",
    "bad_frame_test.to_csv(stats_name_test, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OdXpbPGJ    83.31159\n",
       "dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bad_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OdXpbPGJ    83.473616\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_bad_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_float_64 = []\n",
    "for i  in train_set.columns:\n",
    "    if (train_set[i].dtype == 'float64'):\n",
    "        col_float_64.append(i)\n",
    "        #print(train_set[i].dtype)\n",
    "\n",
    "len(col_float_64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['OdXpbPGJ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "same_cols = []\n",
    "for x,y in zip(col_float_64, train_bad_cols.keys()):\n",
    "    if (x == y):\n",
    "        same_cols.append(x)\n",
    "print(same_cols)\n",
    "len(same_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = train_set.describe()\n",
    "names = ['count','mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "    \n",
    "a['name'] = names\n",
    "a.to_csv(\"a_indiv_train.csv\", index=False)\n",
    "\n",
    "\n",
    "b = test_set.describe()\n",
    "names = ['count','mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "    \n",
    "b['name'] = names\n",
    "b.to_csv(\"a_indiv_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>wJthinfa</th>\n",
       "      <th>ZvEApWrk</th>\n",
       "      <th>vuQrLzvK</th>\n",
       "      <th>FGWqGkmD</th>\n",
       "      <th>qrOrXLPM</th>\n",
       "      <th>BXOWgPgL</th>\n",
       "      <th>umkFMfvA</th>\n",
       "      <th>McFBIGsm</th>\n",
       "      <th>NjDdhqIe</th>\n",
       "      <th>...</th>\n",
       "      <th>IrxBnWxE</th>\n",
       "      <th>BRzuVmyf</th>\n",
       "      <th>dnlnKrAg</th>\n",
       "      <th>VyHofjLM</th>\n",
       "      <th>GrLBZowF</th>\n",
       "      <th>oszSdLhD</th>\n",
       "      <th>aAufyreG</th>\n",
       "      <th>cDhZjxaW</th>\n",
       "      <th>OSmfjCbE</th>\n",
       "      <th>IOMvIGQS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3255.000000</td>\n",
       "      <td>3255.000000</td>\n",
       "      <td>3255.000000</td>\n",
       "      <td>3255.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>3255.000000</td>\n",
       "      <td>2504.000000</td>\n",
       "      <td>890.000000</td>\n",
       "      <td>2504.000000</td>\n",
       "      <td>3255.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>272.000000</td>\n",
       "      <td>1794.000000</td>\n",
       "      <td>532.000000</td>\n",
       "      <td>3255.000000</td>\n",
       "      <td>3255.000000</td>\n",
       "      <td>3255.000000</td>\n",
       "      <td>909.000000</td>\n",
       "      <td>3255.000000</td>\n",
       "      <td>2504.000000</td>\n",
       "      <td>3255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>50057.635023</td>\n",
       "      <td>43.381260</td>\n",
       "      <td>96.040860</td>\n",
       "      <td>17.427343</td>\n",
       "      <td>-7.509967</td>\n",
       "      <td>22.203379</td>\n",
       "      <td>158.354633</td>\n",
       "      <td>-33.279775</td>\n",
       "      <td>301.106230</td>\n",
       "      <td>88.597849</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>45.675585</td>\n",
       "      <td>-15965.135338</td>\n",
       "      <td>1.974808</td>\n",
       "      <td>-249.528111</td>\n",
       "      <td>0.670661</td>\n",
       "      <td>45.782178</td>\n",
       "      <td>-85.937020</td>\n",
       "      <td>-339.568291</td>\n",
       "      <td>78.568356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28615.901302</td>\n",
       "      <td>22.728441</td>\n",
       "      <td>105.556895</td>\n",
       "      <td>72.057949</td>\n",
       "      <td>9.499141</td>\n",
       "      <td>6.962658</td>\n",
       "      <td>124.535287</td>\n",
       "      <td>8.231694</td>\n",
       "      <td>155.904844</td>\n",
       "      <td>107.268927</td>\n",
       "      <td>...</td>\n",
       "      <td>9.097690</td>\n",
       "      <td>41.675286</td>\n",
       "      <td>39.715899</td>\n",
       "      <td>1.565015</td>\n",
       "      <td>322.468103</td>\n",
       "      <td>1.833827</td>\n",
       "      <td>49.499821</td>\n",
       "      <td>114.537914</td>\n",
       "      <td>147.833796</td>\n",
       "      <td>63.123421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>-126.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-125.000000</td>\n",
       "      <td>-53.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>-63.000000</td>\n",
       "      <td>-43.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-61.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-16047.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-5044.000000</td>\n",
       "      <td>-23.000000</td>\n",
       "      <td>-6.000000</td>\n",
       "      <td>-3639.000000</td>\n",
       "      <td>-506.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25938.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>-13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>-36.000000</td>\n",
       "      <td>185.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-15999.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-364.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>-119.000000</td>\n",
       "      <td>-501.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50299.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>-8.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>-36.000000</td>\n",
       "      <td>305.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>-15959.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-184.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>-59.000000</td>\n",
       "      <td>-356.000000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74848.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>138.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>-15927.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-64.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>-39.000000</td>\n",
       "      <td>-256.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99979.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>1069.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>-18.000000</td>\n",
       "      <td>605.000000</td>\n",
       "      <td>1253.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>276.000000</td>\n",
       "      <td>-15911.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>426.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>900.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id     wJthinfa     ZvEApWrk     vuQrLzvK    FGWqGkmD  \\\n",
       "count   3255.000000  3255.000000  3255.000000  3255.000000  602.000000   \n",
       "mean   50057.635023    43.381260    96.040860    17.427343   -7.509967   \n",
       "std    28615.901302    22.728441   105.556895    72.057949    9.499141   \n",
       "min       17.000000  -126.000000    -2.000000  -125.000000  -53.000000   \n",
       "25%    25938.000000    26.000000    33.000000   -39.000000  -13.000000   \n",
       "50%    50299.000000    42.000000    68.000000    27.000000   -8.000000   \n",
       "75%    74848.000000    58.000000   138.000000    77.000000    2.000000   \n",
       "max    99979.000000   122.000000  1069.000000   127.000000    2.000000   \n",
       "\n",
       "          qrOrXLPM     BXOWgPgL    umkFMfvA     McFBIGsm     NjDdhqIe  \\\n",
       "count  3255.000000  2504.000000  890.000000  2504.000000  3255.000000   \n",
       "mean     22.203379   158.354633  -33.279775   301.106230    88.597849   \n",
       "std       6.962658   124.535287    8.231694   155.904844   107.268927   \n",
       "min       8.000000   -40.000000  -63.000000   -43.000000    -7.000000   \n",
       "25%      16.000000    50.000000  -36.000000   185.000000    28.000000   \n",
       "50%      24.000000   150.000000  -36.000000   305.000000    63.000000   \n",
       "75%      24.000000   250.000000  -27.000000   425.000000    98.000000   \n",
       "max      48.000000   500.000000  -18.000000   605.000000  1253.000000   \n",
       "\n",
       "          ...         IrxBnWxE     BRzuVmyf      dnlnKrAg     VyHofjLM  \\\n",
       "count     ...       272.000000  1794.000000    532.000000  3255.000000   \n",
       "mean      ...         0.647059    45.675585 -15965.135338     1.974808   \n",
       "std       ...         9.097690    41.675286     39.715899     1.565015   \n",
       "min       ...       -61.000000     9.000000 -16047.000000    -2.000000   \n",
       "25%       ...         3.000000    21.000000 -15999.000000     2.000000   \n",
       "50%       ...         3.000000    36.000000 -15959.000000     2.000000   \n",
       "75%       ...         3.000000    51.000000 -15927.000000     2.000000   \n",
       "max       ...         3.000000   276.000000 -15911.000000     8.000000   \n",
       "\n",
       "          GrLBZowF     oszSdLhD    aAufyreG     cDhZjxaW     OSmfjCbE  \\\n",
       "count  3255.000000  3255.000000  909.000000  3255.000000  2504.000000   \n",
       "mean   -249.528111     0.670661   45.782178   -85.937020  -339.568291   \n",
       "std     322.468103     1.833827   49.499821   114.537914   147.833796   \n",
       "min   -5044.000000   -23.000000   -6.000000 -3639.000000  -506.000000   \n",
       "25%    -364.000000     1.000000   12.000000  -119.000000  -501.000000   \n",
       "50%    -184.000000     1.000000   39.000000   -59.000000  -356.000000   \n",
       "75%     -64.000000     1.000000   48.000000   -39.000000  -256.000000   \n",
       "max      -4.000000     1.000000  426.000000     1.000000    34.000000   \n",
       "\n",
       "          IOMvIGQS  \n",
       "count  3255.000000  \n",
       "mean     78.568356  \n",
       "std      63.123421  \n",
       "min       0.000000  \n",
       "25%      50.000000  \n",
       "50%      50.000000  \n",
       "75%     100.000000  \n",
       "max     900.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FGWqGkmD', 'BXOWgPgL', 'umkFMfvA', 'McFBIGsm', 'IrxBnWxE', 'BRzuVmyf',\n",
       "       'dnlnKrAg', 'aAufyreG', 'OSmfjCbE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max'], dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "73cd4103-868f-43c3-99d0-85dd974feccb",
    "theme": {
     "58ba9fba-5c9f-48e3-a2d3-c1d1c2ca5a54": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "58ba9fba-5c9f-48e3-a2d3-c1d1c2ca5a54",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         17,
         17,
         17
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         238,
         238,
         238
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         231,
         173,
         82
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         238,
         238,
         238
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "Montserrat",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "Montserrat",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "Montserrat",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "Montserrat",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "Montserrat"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "Montserrat"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "Montserrat"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Open Sans",
        "font-size": 4
       },
       "p": {
        "color": "mainColor",
        "font-family": "Open Sans",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Open Sans",
       "font-size": 4
      }
     },
     "73cd4103-868f-43c3-99d0-85dd974feccb": {
      "backgrounds": {
       "backgroundColor": {
        "background-color": "backgroundColor",
        "id": "backgroundColor"
       }
      },
      "id": "73cd4103-868f-43c3-99d0-85dd974feccb",
      "palette": {
       "backgroundColor": {
        "id": "backgroundColor",
        "rgb": [
         17,
         17,
         17
        ]
       },
       "headingColor": {
        "id": "headingColor",
        "rgb": [
         238,
         238,
         238
        ]
       },
       "linkColor": {
        "id": "linkColor",
        "rgb": [
         231,
         173,
         82
        ]
       },
       "mainColor": {
        "id": "mainColor",
        "rgb": [
         238,
         238,
         238
        ]
       }
      },
      "rules": {
       "a": {
        "color": "linkColor"
       },
       "h1": {
        "color": "headingColor",
        "font-family": "Montserrat",
        "font-size": 7
       },
       "h2": {
        "color": "headingColor",
        "font-family": "Montserrat",
        "font-size": 5
       },
       "h3": {
        "color": "headingColor",
        "font-family": "Montserrat",
        "font-size": 3.75
       },
       "h4": {
        "color": "headingColor",
        "font-family": "Montserrat",
        "font-size": 3
       },
       "h5": {
        "color": "headingColor",
        "font-family": "Montserrat"
       },
       "h6": {
        "color": "headingColor",
        "font-family": "Montserrat"
       },
       "h7": {
        "color": "headingColor",
        "font-family": "Montserrat"
       },
       "li": {
        "color": "mainColor",
        "font-family": "Open Sans",
        "font-size": 4
       },
       "p": {
        "color": "mainColor",
        "font-family": "Open Sans",
        "font-size": 4
       }
      },
      "text-base": {
       "color": "mainColor",
       "font-family": "Open Sans",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
